# 计算机视觉



## 一、计算机视觉简介

![01](C:\Users\何世钊\Desktop\组会分享PPT模板例子\组会分享\AI-learning\01.png)

## 二、图像分类任务

图像分类任务：根据图像信息中所反应的不同特征，把不同类别的图像区分开。从已知的类别标签中为给定输入的图片选定一个类别标签。

### 1、图像分类任务的难点

**语义鸿沟**：建立像素到语义的映射

**视角**：同一图像不同视角下的分类

**光照**：光照对图片的影响

**尺度**：同一物体放大缩小在图像中的尺寸不一样

**遮挡**：外物的遮挡识别

**形变**：如动物在图像中可能表现得姿势、动作不一样

**背景**：背景噪声的影响

### 2、基于规则的分类方法

**图像预处理**：去噪、灰度化、二值化、边缘检测等。

**特征提取**：使用手工设计的特征，如颜色、纹理、形状、边缘等。

**规则定义**：基于阈值、几何形态、统计特性等人为设定规则。

**分类决策**：将提取的特征与设定规则匹配，从而确定类别。

只适用于规则明确，且任务简单的分类任务，如医学检测、工业识别。

### 3、数据驱动的图像分类方法

**数据集构建**

收集用于分类的图形数据，包括图像数据、矢量图（CAD）、结构化图（社交网络图、分子结构图）

数据预处理：数据清洗、格式转换、数据增强、标准化、数据标注

**分类器设计与学习**：

![4061db0869f313e498a5a910ed14d6b5](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\4061db0869f313e498a5a910ed14d6b5.png)

图像表示：像素表示、全局特征表示（GIST：不关注具体对象，提取场景的整体结构信息，不适合遮挡的物体）、局部特征（SIFT ：提取关键点，特征+词袋模型（将图像转换为基于特征的 **直方图表示**））

分类器：近邻分类器、贝叶斯分类器、**线性分类器**、支撑向量机分类器、**神经网络分类器**、随机森林、adaboost。

损失函数：0-1损失、多类支撑向量机损失、交叉熵损失、L1损失、L2损失。

优化算法：迭代优化法：一阶方法（梯度下降、随机梯度下降、小批量随机梯度下将）。二阶方法（牛顿法、BFGS、L-BFGS）。

训练过程：数据集划分、预处理、增强（目标：数据集尽量多）。欠拟合和过拟合（减少算法复杂度，使用权重正则项，使用droput正则化）。超参数（模型设计阶段设置的参数）调整。模型集成。

### 4、指标

**top1**、**top5**

## 三、线性分类器

![99aef87824d17372f2df19cb9b96b4a1](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\99aef87824d17372f2df19cb9b96b4a1.png)

### 1、数据集

**CIFAR10**：50000张训练样本，包括飞机、汽车、鸟、猫、 鹿、狗、蛙、马、船、卡车十个类 别图像为彩色图像，其大小为 32*3。

### 2、图像表示

图像类型：二进制图像、灰度图像（灰0-255白）、彩色图像（RGB，三个深度）

图像转换为向量：将矩阵转换为向量[r1,g1,b1,r2......]

### 3、分类模型

线性分类器：形式简单、易于理解。可以通过层级结构（神经网络）或高维映射（支撑向量机）形成功能强大的非线性模型。

$$
f_i(x,w_i)=w^T_ix=b_i,i=1....c,x表示输入的d维图像向量，c为类别个数,\\w_i=[w_{i1},,,w_{id}]^T为第i个类别的权值向量，b_i为偏置\\
如果f_i(x)>f_j(x),j不等于i，则决策输入图像x属于第i类
$$
每个类都有自己的参数w和b。分别计算，谁最高就是哪个类别。

![4de9c48f21aca95cf6cb1ff20922f59c](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\4de9c48f21aca95cf6cb1ff20922f59c.png)

w记录了类别模板信息的平均值。输入图像与评估模板的匹配程度越高，分类器输出的分数就越高。

线性分类器的决策界面：分数等于0就是决策面，w控制线的方向，b控制线的偏移。离线越远分数越高。

![01dbfeea7254a23cef077256518ac3da](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\01dbfeea7254a23cef077256518ac3da.png)

### 4、损失函数

损失函数是一个函数，用于度量给定分类器的预测值与真实值 的不一致程度，其输出通常是一个非负实值。其输出的非负实值可以作为反馈信号来对分类器参数进行调整， 以降低当前示例对应的损失值，提升分类器的分类效果。
$$
L=\frac{1}{N}\sum_{i=1}L_i(f(X_i,W),y_i)\\x_i表示数据集中的第i张图片；f(x_i,W)表示分类器对x_i的类别预测；\\y_i表示样本i的真实类别标签(整数)；L_i为第i个样本的损失当预测值。
$$

$$
多类支撑向量机\\L_i=\sum_{j\neq y_i}\begin{cases} 
0, & \text{if } s_{y_i} \geq s_{y_i} \\
s_{ij}-s_{y_i}+1, & \text otherwise
\end{cases}
\\=\sum_{j\neq y_i}max(0,S_{ij}-s_{y_i}+1)\\S_{y_i}表示第i个样本真实类别的预测分数，+1是为了远离边界
$$

tips：也称为折页损失。其实就是预测错的分数要比要比正确的高出-1以上才有损失。也可以理解为正确的要比错误的高于1以上，少多少就损失多少。

当w和b很小是，损失L会接近于N-1.可以测试编码正确。

w使L=0，w不唯一。

<img src="C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\7c4b47ebacd801d1250145c01f7a3c14.png" alt="7c4b47ebacd801d1250145c01f7a3c14" style="zoom:200%;" />

### 5、正则向与超参数

$$
L=\frac{1}{N}\sum_{i=1}L_i(f(X_i,W),y_i)+ \lambda R(W)\\R(W)是一个与权值有关，跟图像数据无关的函数。\\\lambda 是一个超参数控制着正则损失在总损失中所占的比重。\\L=数据损失+正则损失
$$

**超参数**：在开始学习过程之前设置值的参数，而不是学习得到。对模型性能有重要影响。

L2正则项 ：让模型有了偏好，解决了w不唯一。
$$
R(W)=\sum_k\sum_lW^2_{k,l}\\L2正则损失对大数值权值进行惩罚，喜欢分散权值，鼓励分类器经所有维度的特征都利用起来，而不是依赖少数几维特征。
$$
![015ae5d295630f1b581e30cc61246d2b](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\015ae5d295630f1b581e30cc61246d2b.png)

**tips**：防止过拟合。

### 6、优化算法

参数优化：利用损失值作为反馈信号调整分类参数，提升分类器性能。
$$
直接方法:\\\frac{\partial L}{\partial W}=0
$$
**梯度下降算法**

​	采取负梯度方法，设置学习率（及步长）
$$
L(W)=\frac1N\sum_{i=1}^N{L_i(x_i,y_i,W)+\lambda R(W)}
\\while True
\\权值的梯度\leftarrow 计算梯度（损失，训练样本，权值）\\权值\leftarrow 权值-学习率*权值的梯度
$$
**求梯度：**

​	1.数值法(慢，且不精确，用于解析梯度的正确性)
$$
\frac {dL(w)}{dw}=lim_{h\rightarrow0}\frac{L(w+h)-L(w)}{h}
$$
​	2.解析法（精确，速度块，导数函数求导容易出错）

随机梯度下降算法：每次随机选择一个样本xi,计算损失并更新梯度（单个样本可能会带来很多噪声，不是每次更新都向优化的方向）

小批量随机梯度下降算法：每次随机选m个样本，iteration：一次迭代；batch-size(2的幂数)：一次样本所用的样本量；epoch：一个epoch表示迭代了一边训练集中的所有样本（不是每个都过了一遍）。

### 7、数据集划分

训练集（用给定的超参数寻找最优分类器，不同的超参数学习不同的模型）和测试集（评测泛化能力），验证集（选择超参数）

**K折交叉验证**（数据很少，不好划分）：对于训练集，按折数平均分配，每一次选择一部分作为验证集，训练n次，最终取平均

带有打乱数据的的重复k折验证，每次一有训练打乱一次数据，随机性更强。

### 8、数据集预处理

神经网络：去均值（数据分布在中心附近），机器学习：归一化（相同尺度），去相关（降维），白化。

## 四、全连接神经网络

![1744031038(1)](C:\temp\1744031038(1).png)

### 1、全连接神经网络

$$
两层全连接神经网络 f=w_2max(0,W_1+b_1)+b_2
\\三层全连接神经网络 f=W_3max(0,w_2max(0,W_1+b_1)+b_2)
$$

![1744032852(1)](C:\temp\1744032852(1).png)

![1744032928(1)](C:\temp\1744032928(1).png)

W1的行数可以指定，也可以理解为模板；W2融合多个模板的匹配结果来实现最终类别打分。

max是激活函数

W1=100*3072，max是对每行都与0进行比较。W2行由样本决定，列数由w1决定。b1是100行1列

w1的行数等于增加模板的个数，分类器有机会学到更多的模板。

线性可分：至少存在一个线性分界面能把两类样本分开。全连接神经网络的分类器界面可以是曲线。解决线性不可分问题。

### 2、激活函数

如果缺少了激活函数，全连接神经网络将变成一个线性分类器

![1744033271(1)](C:\temp\1744033271(1).png)

sigmoid:将数据压缩到0-1；tanh将数据压缩到-1~1；ReLU：小于0就等于0；leakyReLU：小于0就减小10倍。

网络结构设计：深度设计：用不用隐层，用几个隐层；宽度设计：每层设置多少神经元合适。激活函数的选择。神经元个数越多，分界面就越复杂，在这个集合上的分类能力越强，但是容易过拟合。输入层和输出层的神经元个数由任务决定，而隐层数量以及隐层的神经元个数需要人为指定。

### 3、softmax与交叉熵

softmax:输出层打分变成概率。先取指数，再归一化得到概率。

交叉熵损失：比较预测分布和真实分布的损失

相对熵：也叫KL散度，用来度量两个分布之间的不相似性。
$$
分类器预测分布q(x),真实分布p(x)\\熵：H(p)=-\sum_x{p(x)logp(x)}\\交叉熵：H(p,q)=-\sum_x{p(x)logq(x)}\\相对熵：KL(p||q)=-\sum_xp(x)log\frac{q(x)}{p(x)}\\三者之间的关系：H(p,q)=H(p)+KL(p||q)\\交叉熵损失：-\sum^c_{i=1}{p(x_i)log(q(x_i))}\\Tip:当真实分布为one-hot（1，0，0）形式时，交叉熵损失简化为L_i=-log(q_j)
$$
交叉熵损失可以比多类支撑向量机精度更高。

![1744097979(1)](C:\temp\1744097979(1).png)

### 3、优化算法

#### 	计算图：

​	![1744098441(1)](C:\temp\1744098441(1).png)	

​	任何复杂的函数，都可以用计算图的形式表示在整个计算图中，每个门单元都会得到一些输入，然后，进行下面两个计算： 

​		a)这个门的输出值 

​		b)其输出值关于输入值的局部梯度。 

​	利用链式法则，门单元应该将回传的梯度乘以它对其的输入的局部梯度，从 而得到整个网络的输出对该门单元的每个输入值的梯度

​	计算图的颗粒度：利用已知函数的导数简化计算过程，增大颗粒度。

![1744099041(1)](C:\temp\1744099041(1).png)

#### 	激活函数：

​		梯度消失：某个局部梯度为0，由于链式法则的乘法导致梯度消失。例如sigmoid和tanh激活函数，ReLU小于0会梯度为0.Leakly ReLU基本（0）没有死区

​		梯度爆炸：断崖处梯度乘以学习率后 会是一个非常大得值，从而“飞”出 了合理区域，最终导致算法不收敛；解决方案：把沿梯度方向前进的步长 限制在	某个值内就可以避免“飞”出 了，这个方法也称为梯度裁剪。

​	尽量选择ReLU和Leakly ReLU。

#### 	动量法

![1744100350(1)](C:\temp\1744100350(1).png)

![1744100404(1)](C:\temp\1744100404(1).png)

### 自适应梯度法

减小震荡方向步长，增大平坦方向步长来减小震荡，加速通往谷底方向。震荡方向：梯度的平方较大的，平坦方向：平方较小的的方向。

AdaGrad算法没有p，累加时间过长r会变得很大，失去调节作用。

![1744100609(1)](C:\temp\1744100609(1).png)

#### Adam

![1744101113(1)](C:\temp\1744101113(1).png)

一开始用ADAM，速度快，动量法＋SGD效果更好。

### 4、卷积核权值初始化

避免全0初始化，采用随机初始化。

有效的初始化方法：使网络各层的激活值和局部梯度的方差在传 播过程中尽量保持一致；以保持网络中正向和反向数据流动。防止前向传播的信息消失，也可以解决反向传递过程中的梯度消失。

**Xavier初始化**，权值采样自N（0，1/N）的高斯分布，N为输入神经元个数，适用于tanh激活函数。

**HE初始化**，权值采样自N（0，2/N）的高斯分布，N为输入神经元个数，适用于ReLU和leakly ReLU激活函数。

### 5、批归一化

直接对神经元的输出进行批归一化，对输出进行减均值除方差，保证当前神经元的输出值符合0均值1方差。经常插入到全连接测后非线性激活前。

![1744102819(1)](C:\temp\1744102819(1).png)

![1744102850(1)](C:\temp\1744102850(1).png)

平移缩放：根据分类的贡献自行决定分布的均值和方差。

单张样本测试时，均值方差的设置，来自于训练中每个批次的均值和方差，最后取平均作为测试时的均值和方差。

### 6、欠拟合、过拟合现象和Dropout

过拟合，对已知数据预测的很好，对未知数据预测的很差。模型只记住了训练数据，而不是学习到了特征。

欠拟合：模型描述能力太弱，不能很好学习到数据中的规律，模型过于简单。

机器学习的根本问题时优化和泛化的问题，优化：指模型在训练数据上得到最佳性能，泛化：训练好的模型在未见过的数据上的性能好坏。

![1744103764(1)](C:\temp\1744103764(1).png)

最优方法：获取更多的训练数据，次优方案：调整模型允许存储的信息量或者对模型允许存储的信息加以 约束，该类方法也称为正则化。随机失活（dropout）

![1744104234](C:\temp\1744104234.png)

**dropout**：

 	让隐层的神经元以一定的概率不被激活。训练过程中，对某一层使用Dropout，就是随机将该层的一些输出舍弃(输出值 设置为0），这些被舍弃的神经元就好像被网络删除了一样。

​	随机失活比率（Dropout ratio）：是被设为0 的特征所占的比例，通常在0.2～0.5范 围内。

​	随机失活使得每次更新梯度时参与计算的网络参数减少了，降低了模型容量， 所以能防止过拟合。随机失活鼓励权重分散，从这 个角度来看随机失活也能起到 正则化的作用，进而防止过拟合。Dropout可以看作模型集成。测试阶段所有的神经元全部打开，不会失活，所以要除p

![1744105000(1)](C:\temp\1744105000(1).png)

### 7、神经网络的超参数

网络结构：隐层神经元个数，网络层数，非线性单元选择。优化相关：学习率，dropout比率，正则项强度。

**学习率：**过大无法收敛，偏大会在最小值附近震荡，达不到最优；学习率偏小收敛时间长。

![1744105654(1)](C:\temp\1744105654(1).png)

超参数搜索策略：粗搜索：利用随机法在较大范围内采样超参数，利用验证集正确率缩小超参数范围。精搜索：在小范围内采样超参数运行五到十个周期，选择验证集上精度最高的参数。

超参数的标尺空间：在对数空间内进行随机采样。

学习率调成方法：当损失不在变化，选择更小的学习效率继续训练。

## 五、卷积、图像去噪、边缘提取、纹理表示和卷积神经网络

### 1、卷积与图像去噪

![1744113814(1)](C:\temp\1744113814(1).png)

噪声：某个像素点和周围插值过大，取平均后去噪。一个去噪就是一次卷积。

卷积要将图像旋转180

边界填充（保证图像尺寸）：zero-pedding；拉伸；镜像。卷积模板就是需要计算的尺寸的大小。就是每个像素所占的比例。

![1744113842(1)](C:\temp\1744113842(1).png)

### 2、高斯卷积核

平均卷积核：卷积后产生一些水平和竖直的条状（振铃），解决：根据距中心的距离分配权重
$$
高斯函数\\G_\sigma=\frac{1}{2\pi\sigma^2}e^{-\frac{(x^2+y^2)}{2\sigma^2}}
$$
高斯卷积核的生成步骤：

​	1.确定卷积核尺寸，例如3*3

​	2.设置高斯函数的标准差，比如σ=1

​	3.计算卷积核各个位置的权重值

​	4.对权重进行归一化（平滑模板）

方差越大，平滑效果越明显。尺寸越大，平滑效果越强。

经验法则：将卷积核的半窗宽度设置为3σ，最终卷积模板宽度为2*3σ+1.

性质：去除图像中的”高频“成分（低通滤波器）；两个高斯卷积核后得到的还是高斯卷积核：使用多次小方差卷积核连续卷积，可以得到与大方差卷积核相同的结果，使用标准差为σ的高斯核进行两次卷积后与使用标准差根号2倍σ的高斯核进行一次卷积相同（减少运算量核计算复杂度）。可分离：二维可分离为两个一维的卷积（降低运算量）。
$$
σ_1,\sigma_2两次卷积=\sqrt{\sigma_1^2+\sigma_2^2}
$$

### 3、图像噪声与中值滤波

噪声：椒盐噪声：黑白像素随机出现；脉冲噪声：白色像素随机出现；高斯噪声：噪声强度变化服从高斯分布（正态分布）

![1744116053(1)](C:\temp\1744116053(1).png)

高斯噪声越大，要用σ越大的高斯卷积。但会去除某些特征。适用于高斯噪声

**中值滤波**：将模板的像素进行排序，取中值作为像素点的像素。非线性滤波，适用于椒盐和脉冲噪声

### 4、边缘提取

边缘：图像中亮度明显而急剧变化的点。种类：表面法相不连续；深度不连续；颜色不连续；光照不连续。

边缘检测：对一维信号进行求导。
$$
 图像求导公式：\\\frac{\part f(x,y)}{\part x}\approx \frac {f(x+1,y)-f(x,y)}{1}
$$
![1744116961(1)](C:\temp\1744116961(1).png)

图像梯度：指向灰度变换最快的方向。



| ![1744117156(1)](C:\temp\1744117156(1).png) | ![1744117242(1)](C:\temp\1744117242(1).png) |
| :------------------------------------------ | ------------------------------------------- |

噪声影响求导，要先高斯去噪，对去噪后的图像进行求导。微分是卷积，而卷积具有结合性。可以先对高斯模板进行求导，在对图像进行卷积。

高斯一阶偏导卷积核越大，提取的颗粒度越大。

 高斯核 ➢ 消除高频成分（低通滤波器） ➢ 卷积核中的权值不可为负数 ➢ 权值总和为1（恒定区域不受卷积影响）

 高斯一阶偏导核 ➢ 高斯的导数 ➢ 卷积核中的权值可以为负 ➢ 权值总和是0（恒定区域无响应） ➢ 高对比度点的响应值大

非最大化抑制：保留梯度方向上最大的值。得到更为准确的边缘。

Canny边缘检测器：去除边缘噪声。

1. 用高斯一阶偏导核卷积图像 

2. 计算每个点的梯度幅值和方向 

3. 非极大值抑制： 将宽的“边缘”细化至单个像素宽度 

4. 连接与阈值（滞后）： 

   • 定义两个阈值：低和高 

   • 使用高阈值开始边缘曲线，使用低阈值继续边缘曲线，只保留和高阈值连接的边。

## 六、纹理表示与卷积神经网络

纹理：规则纹理（人为），随机纹理。

### 1、基于卷积核组的纹理表示方法

![1744118605(1)](C:\temp\1744118605(1).png)

纹理分类任务：不关注基元位置，只关注出现了那种基元以及基元出现的频率。

![1744119010](C:\temp\1744119010.png)

### 2、卷积神经网络

![1744121461(1)](C:\temp\1744121461(1).png)

**卷积层**：

![1744120304(1)](C:\temp\1744120304(1).png)

卷积核的深度=输入的特征响应图组的深度=上一个卷积测的卷积核的个数。

**卷积步长**：卷积核可以按照指定的间隔进行卷积操作。这个间隔就是卷积步长。

![1744120571(1)](C:\temp\1744120571(1).png)

**边界填充**：保持输入输出的尺寸一致。0值填充

![1744120738(1)](C:\temp\1744120738(1).png)

![1744120843(1)](C:\temp\1744120843(1).png)

**激活函数层**：ReLU

**pooling层：**池化操作。对于每个特征响应图独立及逆行，降低特征响应图组中每个特征相应图的宽度和高度，减少后续卷积层的参数的数量，降低计算资源消耗，进而控制过拟合。

​	池化操作（对特征相应图莫格区域内进行池化就是在该区域指定一个值来代表整个区域）：平均池化，最大池化。有重叠池化，无重叠池化。

**损失函数**：交叉熵损失

优化算法：SGD、带动量的SGD以及ADAM

**图像增强**：

​	问题：过拟合的原因是学习样本太少，导致无法训练出能够泛化到新数 据的模型。

​	数据增强：是从现有的训练样本中生成更多的训练数据，其方法是利用多种能够生成可信图像的随机变换来增加样本。

​	 数据增强的目标：模型在训练时不会两次查看完全相同的图像。这让模型能够观察到数据的更多内容，从而具有更好的泛化能力

样本增强：反转，随机缩放，抠图，色彩抖动，拉伸。

## 六、经典网络分析

### 1、AlexNet

贡献：

1.提出了一种卷积层加全连接层的卷积神经网络结构 

2.首次使用ReLU函数做为神经网络的激活函数 

3.首次提出Dropout正则化来控制过拟合 

4.使用加入动量的小批量梯度下降算法加速了训练过程的收敛；

5.使用数据增强策略极大地抑制了训练过程的过拟合； 

6.利用了GPU的并行计算能力，加速了网络的训练与推断。

共8层：5个卷积层，3个全连接层。

![1744275378(1)](C:\temp\1744275378(1).png)

tip：输入网络之前要去均值，及把数据集的所有数据取均值，图片向量减去这个均值。我们需要的是插值，输出尺寸=（H-F+2P）/S+1

**maxpool1**：窗口大小3*3，步长为2，输出的尺寸为27，特征图个数96.

**norm1**：局部响应归一化层。提升效果不明显，现在已经不使用

**conv2**：256个5*5卷积核，步长为1，使用0填充p=2。输出尺寸=27，256个特征图

**第三四层（conv3、conv4）**384个3*3卷积核，步长为1，使用0填充p=1。输入尺寸13，256个特征图组

**conv5**：256个3*3卷积核，步长为1，使用0填充。

池化玩6* 6 *256的特征图组

**FC678**：展开为9216维向量。输入全连接神经网络

用于提取图像特征的卷积层和用于分类的全连接层是同时学习的。

技巧：1. Dropout策略防止过拟合；2.使用加入动量的随机梯度下降算法，加速收敛；3.验证集损失不下降时，手动降低10倍的学习率；4.采用样本增强策略增加训练样本数量，防止过拟合；5.集成多个模型，进一步提高精度。分布于GPU上运算。

AlexNet：卷积层类似于用了256个超级卷积核组提取特征。6*6表示原图中具有某个特征。（可以取均值，减小计算量）

### 2、ZFNet

![1744278013(1)](C:\temp\1744278013(1).png)

1.保留更多细粒度的信息，增加卷积核数量可以让网络学习到更多的特征。

### 3、VGG

![1744278466(1)](C:\temp\1744278466(1).png)

VGG16的取均值，是以像素为单位，计算每个像素的RGB的均值，输入图像减去这个均值。

![1744278610(1)](C:\temp\1744278610(1).png)

![1744278726(1)](C:\temp\1744278726(1).png)

小卷积核的优势：多个小卷积核串联可以的得到与大尺寸卷积核相同的感受野。2个3* 3感受野为5 * 5；3个3 * 3为7*7.

![1744279090(1)](C:\temp\1744279090(1).png)

每经过一次池化操作，卷积核个数就增加一倍。池化操作可以减少特征图尺寸，降低现存占用；增加卷积核个数有助于学习更多的结构特征，但会增加网络参数以及内存消耗；以增一减的设计平衡了识别精度与存储、计算开销。提升了网络性能。

为什么提升到512就不在增加：第一个全连接层含102M参数，占总参数个数的0.74；这一层的参数个数是特征图尺寸与个数的成绩，参数过多容易过拟合。

### 4、GoogleNet

![1744279601(1)](C:\temp\1744279601(1).png)

串联结构（VGG）存在的问题：后面的卷积层只能处理前层的输入信息，会丢掉很多新信息。

![1744280002(1)](C:\temp\1744280002(1).png)

Inception:1*1的卷积不改变空间信息，对深度信息进行压缩，通过设置1 * 1卷积核的个数，压缩输入图组的深度；3 * 3和5 * 5提取局部结构信息，maxpoling对信息进行放大加强。filter对输出信息进行拼接。H和W保持不变

InceptionV1:加两个1 * 1的卷积核，减低运算量

辅助分类器避免梯度消失。最后采用平均池化代替直接展开向量化，丢失位置信息（只需要关注有没有这种特征而不是关注特征在哪），减少了参数，有利于提升卷积层提取到的特征的平移不变性。可以减少全连接层的个数，从而减少参数

### 5、ResNet

![1744285681(1)](C:\temp\1744285681(1).png)

更深的层数会导致错误率提升，因为，层数越深信息流通不通畅,中间有一个relu操作，引入非线性，，使模型具有更强的表达能力。

**残差连接**：正向和反向的信息可以顺利通过，即使某层的梯度为0，因为堆叠了输入的数据，可以保证梯度顺利传播。残差：F（x）=H（x）-x

![1744286116(1)](C:\temp\1744286116(1).png)

“瓶颈机构”：第一个1 * 1为了减少计算量，第二个1 * *1为了升维，让残差可以和输入相加

![1744286319(1)](C:\temp\1744286319(1).png)

性能好的原因：残差网络可以看成一种集成模型

![1744286397(1)](C:\temp\1744286397(1).png)

## 七、图像分割

视觉识别的任务：分类（不考虑空间位置）、语义分割（像素类别），目标检测、实例分割

### 1、**语义分割**：给每个像素分类标签，不区分实例，只考虑像素类别

方法1.滑窗口，利用cnn对中心点像素分类（效率低，某些像素会重复计算）2.全卷积，让整个网络只包含卷积层，一次性输出所有像素的类别预测（处理过程中,如果保持原始分辨率，对现存需求会爆）

![1744446304(1)](C:\temp\1744446304(1).png)

上采样方法：转置卷积：

![1744449272(1)](C:\temp\1744449272(1).png)

### 2、目标检测

**单目标**（分类+定位，多任务网络）：多任务损失；分别卷积位置与分类预测；计算多任务损失；利用训练好的模型，在训练位置网络；然后一起训练。不能用于多目标，因为不确定有多少目标。

![1744531505(1)](C:\temp\1744531505(1).png)

**多目标**：目标数量不确定

1.滑动窗口：对图像中所有可能的区域（不同位置、尺寸、长宽比）进行分类，计算量巨大。

2.基于区域的目标检测算法

​	找出所有潜在可能包含目标的区域；运行速度需要相对较快；比如，Selective Search在CPU上仅需要运行几 秒钟就可以产生2000个候选区域。

​	候选图像区域可能是目标的一部分，就需要Bboxreg（边界框回归）去学习微调边界框，使其能更准确地框住目标。

​	![1744533074(1)](C:\temp\1744533074(1).png)

Fast-R-CNN（端到端的网络）：先对图像进行卷积，然后再利用感兴区域提取特征进行训练。不用重复计算，直接在特征上裁剪。

![1744533351(1)](C:\temp\1744533351(1).png)

区域裁剪：

![1744533669(1)](C:\temp\1744533669(1).png)

![1744533873(1)](C:\temp\1744533873(1).png)

然后进行最大池化。

问题：候选区域产生过程耗时过高，几乎等于单张图片的检测时间。

Faster R-CNN：对特征图候选区域

![1744535028(1)](C:\temp\1744535028(1).png)

4表示定位参数量（边界中心坐标，宽和高），锚点代表原图卷积前的区域特征。但是锚点的区域可能是目标的一部分，所以采用多种尺寸的锚点区域。

![1744535942(1)](C:\temp\1744535942(1).png)

四种损失联合训练： • RPN分类损失(目标/非目标）二分类 • RPN边界框坐标回归损失 • 候选区域分类损失 • 最终边界框坐标回归损失

Rol pooling只回传主干网络上的梯度。

第一阶段: 每张图运行一次 ➢ 主干网络(Backbone) ➢ 区域建议网络(RPN) 第二阶段: 每个区域运行一次 ➢ 扣取区域特征: RoIpool /align ➢ 预测目标类别 ➢ 预测边界框偏移量。

yolo，只用第一阶段，直接将图像分成7*7的网格，每个anchor预测B个边界框，每个边界框有5维（x,y,h,w confidence(置信度)），对每个anchor进行预测。

ssd：用多层特征，对多层特征进行融合。

影响目标检测的精度：主干网络（VGG，ResNet。。。。），主干网越深越宽，性能越好；基础架构：两阶段（faster-cnn）；一阶段（yolo，SSD）；混合（R-FCN）；图像尺寸；区域建议个数。

Faster R-CNN速度慢但精度高； SSD速度快，相对于Faster  R-CNN精度有所欠缺

### 3、实例分割（Mask R-CNN）

![1744537277(1)](C:\temp\1744537277(1).png)

## 八、可视化

反向可视化：基于反向传播原理，从神经网络输出层反向传递信号 。以图像领域为例，通过计算输出对输入图像像素的梯度，来确定哪些像素对网络决策影响大。比如在分类猫和狗的任务中，能找出图像中对判断是猫还是狗起关键作用的区域。

**梯度上升法：**CNN 通过多层卷积和池化操作对输入图像进行特征提取和抽象。梯度上升法的核心思想是，从一个随机初始化的图像开始，通过计算目标特征（如某一层的特征图）关于输入图像的梯度，并沿着梯度上升的方向更新输入图像，使得目标特征的值逐渐增大。这样，经过多次迭代后，输入图像会逐渐演化成能够最大化激活目标特征的图像，从而可视化出该特征所对应的模式或信息。

### 具体步骤

1. **初始化输入图像**：通常使用随机噪声图像作为初始输入，其大小与网络的输入图像尺寸一致。例如，对于一个处理 RGB 图像的 CNN，输入图像的形状可能是 (3, height, width)，其中 3 表示颜色通道数。
2. **选择目标特征**：确定要可视化的 CNN 中的目标特征，可以是某一层的某个特征图，或者是多个特征图的组合。例如，选择网络中间某一层的第 10 个特征图作为目标。
3. **前向传播**：将输入图像输入到 CNN 中，进行前向传播，计算出目标特征的值。
4. **计算梯度**：计算目标特征关于输入图像的梯度。这一步通常使用自动求导工具（如 PyTorch 或 TensorFlow 中的自动求导功能）来实现。
5. **更新输入图像**：沿着梯度上升的方向更新输入图像，通常通过将梯度乘以一个学习率（步长），然后加到输入图像上。例如，`input_image = input_image + learning_rate * gradient`。
6. **重复迭代**：重复步骤 3 到 5，进行多次迭代，直到目标特征的值达到一定的稳定状态或满足预设的停止条件。
7. **可视化结果**：经过多次迭代后，得到的输入图像就是能够最大化激活目标特征的图像，可以对其进行可视化展示，从而观察该特征所对应的模式或信息。

层数越高，关注的是更具体的信息。

**对抗样本：**通过对原始输入数据（如图像、文本等）添加精心设计的微小扰动，生成的能使机器学习模型（尤其是深度神经网络）做出错误预测的样本。这些扰动通常非常小，小到几乎无法被人类察觉，但却能对模型的输出产生重大影响。

​	**基于梯度的方法**：利用模型输出关于输入的梯度信息来生成扰动。例如快速梯度符号法（FGSM），它根据目标函数对输入的梯度方向，以固定步长在输入上添加扰动，从而改变模型的预测结果。公式为*x*′=*x*+*ϵ*⋅*s**i**g**n*(∇*x**J*(*θ*,*x*,*y*))，其中*x*是原始输入，*x*′是对抗样本，*ϵ*是控制扰动大小的超参数，∇*x**J*(*θ*,*x*,*y*)是损失函数*J*关于输入*x*的梯度，*s**i**g**n*是符号函数。

​	**迭代方法**：多次应用基于梯度的方法来逐步优化扰动，如迭代快速梯度符号法（I-FGSM）。它通过多次迭代计算梯度并添加扰动，每次迭代的步长较小，相比 FGSM 能生成更具攻击性的对抗样本。

​	**模型攻击法**：利用其他模型来生成对抗样本，例如生成对抗网络（GAN）。通过训练一个生成器网络，使其生成能够欺骗目标模型的对抗样本。

**DeepDream**：，让网络去强化那些它 “擅长识别” 的特征。比如在一个已经训练好的用于识别动物的网络中，某一层可能对眼睛、耳朵等特征比较敏感，DeepDream 就会增强这些特征，使得图像朝着更能激活该层神经元的方向变化。

- **选择预训练模型**：通常使用在大规模图像数据集（如 ImageNet）上预训练好的卷积神经网络，如 GoogLeNet 等。
- **输入图像**：将想要处理的原始图像输入到预训练模型中。
- **选择目标层**：确定要增强其激活值的卷积层。一般选择中间层，因为底层可能只捕捉简单的纹理，高层则更关注整体的物体类别，中间层往往能产生比较有趣的视觉效果。
- **计算梯度**：计算目标层激活值关于输入图像的梯度，以确定如何修改图像能增加该层的激活。
- **更新图像**：根据计算得到的梯度，对输入图像进行调整，通常是沿着梯度上升的方向，使目标层的激活值增大。这个过程可能会反复迭代多次，每次迭代都会让图像变得更加 “梦幻”。
- **调整尺度**：为了生成更丰富的细节和效果，还会采用多尺度处理，即对图像进行不同尺度的缩放，在每个尺度上都应用上述过程，然后将结果融合起来。

**feature inversion（特征反演）**：从神经网络提取的特征向量反向重构出原始输入或近似输入

**Neural Texture Synthesis（纹理合成）**：分析样本纹理的特征，然后按照一定的规则将这些特征复制、组合或变形，以创建新的纹理。

**Neural Style Transfer**：利用深度学习技术将一幅图像的风格迁移到另一幅图像上的方法，其核心是结合内容和风格信息，生成具有独特艺术效果的图像。

![1744546249(1)](C:\temp\1744546249(1).png)

可视化工具keras-vis

## 九、生成模型VAE

有监督学习：数据（x,y）x表示样本，y表示标签，学习样本到标签的映射。分类，回归，目标检测，语义分割

无监督学习：数据x，找出隐含在数据里的模式或结构；例如：K-means聚类，降维，特征学习，密度估计等

生成模型：给定训练集，产生与训练集同分布的新样本。及密度估计问题。显示的密度估计：显示的定义并求解分布P，隐式的密度估计：学习一个模型p，而无需定义它。图像合成，图像属性编辑，图像风格转移，域适应。

### 1、PixeRNN与PixelCNN（显式的密度）

$$
给定已经生成的像素的前提下生成第i个像素的概率，需要定义像素产生的概率\\p(x)=\prod _{i=1}^n p(x_i|x_1,,,,X_{i-1})
$$

PixeRNN：从左上角开始产生像素，将像素生成看成一个序列生成的问题，缺点；序列生成太慢了

PixeCNN：还是从左上角产生像素，基于已经生成的像素，利用卷积生成下一个像素。也很慢

可以精确计算似然函数，利用似然函数的值可以有效评估模型性能。序列产生太慢



### 2、VAE（显示密度，可以定义，但是求不出来）

![894004249e6f6f031321a9204c59a872](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\894004249e6f6f031321a9204c59a872.png)

用重构损失来训练低维的特征表示，不需要标签

![0466f883a7d19dad44e4e7d5d139636e](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\0466f883a7d19dad44e4e7d5d139636e.png)

可以用训练后的编码器作为监督学习的初始特征提取模型，加入全连接神经网络，预测标签，计算损失函数微调编码器参数，利用少量数据训练最终网络，但是性能没有直接用卷积神经网络好。

缺点：只能生成已知图像的数据的图片，两张图片的融合无法生成

**变分自编码器（VAE）**

![93f9d7d1a508f128c91b613041361eee](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\93f9d7d1a508f128c91b613041361eee.png)

![8f1cfb3043024d5ef10e0746d5723947](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\8f1cfb3043024d5ef10e0746d5723947.png)

输入图像，生成的不是z而是均值m，标准差exp（σ）的分布，e1就是采样值。从标准正态分布采样的值。

tip：也可以用relu函数确保σ非负直接作为方差。

损失函数：1.L损失；2.最小化，希望σ接近于1，m（L2正则化）希望归一化，越小越接近于0越好。就是希望中间产生的高斯分布接近0均值1方差，另外也可以采用均匀分布，但要改正则化函数。真实使用可以直接从标准正态分布中采样生成图像

优点：可以计算q（z|x）(密度函数)

问题：vae并没有真的模仿真实图片，只是记住了存在的图像。产生的样本比较模糊，质量较低。

## 十、GAN（隐式生成）生成对抗网络

问题：希望从训练样本分布中采样新数据，但这个分布不仅维度高而且还很复杂，难以直接实现。

解决方案: 对一个简单的分布采样，比如均匀分布；然后，学习一种映射将其变换到训练样本分布。可以用神经网络，类似于解码器，这里定义为生成网络。

![1b0c4dec76c06156f1141c2d2cedcf19](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\1b0c4dec76c06156f1141c2d2cedcf19.png)

生成对抗网络：生成器的任务是生成与真实数据相似的样本，而判别器的任务是区分输入的样本是真实数据还是生成器生成的假数据。两个网络通过对抗训练的方式不断提升性能，最终生成器能够生成高质量的样本。

**生成器（Generator）**：接受一个随机噪声向量作为输入，通过一系列的神经网络层将其转换为与真实数据具有相同维度的样本。生成器的目标是学习真实数据的分布，使得生成的样本能够骗过判别器。

**判别器（Discriminator）**：接受真实数据样本和生成器生成的假数据样本作为输入，输出一个概率值，表示输入样本是真实数据的概率。判别器的目标是尽可能准确地区分真实数据和假数据。

GAN 的训练过程是一个博弈的过程，生成器和判别器交替进行训练：

1. **训练判别器**：固定生成器的参数，从真实数据集中采样一批真实样本，同时从噪声分布中采样一批噪声向量输入到生成器中得到一批假样本。将真实样本和假样本分别输入到判别器中，计算判别器的损失函数（通常使用二元交叉熵损失），并通过反向传播更新判别器的参数，使得判别器能够更好地区分真实数据和假数据。
2. **训练生成器**：固定判别器的参数，从噪声分布中采样一批噪声向量输入到生成器中得到一批假样本。将这些假样本输入到判别器中，计算生成器的损失函数，目标是最大化判别器将假样本判断为真实数据的概率。通过反向传播更新生成器的参数，使得生成器能够生成更逼真的样本。
3. **重复步骤 1 和 2**：直到生成器和判别器达到一个平衡状态，生成器能够生成高质量的样本，判别器难以区分真实数据和生成的假数据。

$$
D是对判别器对样本为真的判别，G是生成器根据噪声生成的样本,判别器输出真实图片的似然[0,1]
\\min_{\theta_g}是生成器希望最小化目标函数使D_{\theta_d}(G_{\theta_g}(z))尽量接近于1，及希望判别器认为生成器产生的图像为真
\\max_{\theta_d}是判别器希望最大化目标函数使D(x)接近于1,而D(G(z))接近于0(假样本)
\\min_{\theta_g}max_{\theta_d}=E_{x∼p_{data}}logD_{\theta_d}(x)+E_{z∼p_{(z)}}[log(1−D_{\theta_d}(G_{\theta_g}(z)))]
$$

| ![4ee9b34016c1c9b98166dbdbd5faf0d1](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\4ee9b34016c1c9b98166dbdbd5faf0d1.png) | ![fdf65b2dd1485a7be7c73a75dc5c3b59](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\fdf65b2dd1485a7be7c73a75dc5c3b59.png) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

![612ec117e11f2684c057079981d70890](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\612ec117e11f2684c057079981d70890.png)

GAN:很难训练，非常不稳定，无法计算样本的概率，

优化：更好的损失函数，更稳定的训练方法

### DCGAN

![dca47712130d1dcd677ae4eb5324ec89](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\dca47712130d1dcd677ae4eb5324ec89.png)

### GAN优化

JS散度的问题：当产生样本和真实样本不重叠时，js都等于log2，没有梯度无法进行更新。D过于强大，一些点距离决策边界过远，没有梯度，无法训练。

LSGAN：将判别器任务由分类改为回归任务

​	gan的损失函数基于交叉熵，Lsgan改为最小二乘损失。希望最小化真实样本与生成样本的判别结果与真实标签之间的均方误差，最后也没有sigmoid函数

![788027cd17b20714a25c53a29b039e7f](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\788027cd17b20714a25c53a29b039e7f.png)

WGAN：（wasserstein）推土机距离，将分布搬运到真实分布的距离， 所有的方案中最小的距离。

​	wgan的判别器没有sigmoid函数,直接输出一个实数，表示样本的质量或得分，取值不受限制，而GAN最后有一层simoid函数将输出映射到0-1，表示样本属于真实分布的概率。

​	wgan对判别器权重进行限制，保证Lipschitz 连续的这是因为 Wasserstein 距离的计算依赖于判别器满足一定的光滑性条件。通过限制判别器的权重，使得判别器满足 Lipschitz 条件，可以保证判别器在训练过程中不会出现剧烈的变化，从而提高训练的稳定性和收敛性。

![bfb3c72c8d6c8aab9fa4a735ba4cb50a](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\bfb3c72c8d6c8aab9fa4a735ba4cb50a.png)

### 条件GAN

存在标签一对多的问题，传统神经网络的输出结果和每个训练样本都接近，生成图片比较模糊。

![a665b022a40a9f237530ae302e9b6fe0](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\a665b022a40a9f237530ae302e9b6fe0.png)

SGAN：在判别真假的的同时，输出真是图像的类别。分类+判别

ACGAN：CGAN+SGAN+分类损失（即关注真样本类别信息也关注假样本类别信息）

infoGAN：在判别真假的的同时，输入和输出的隐变量关联变大，输出隐变量和fake的互信息越大越好，可以通过改变隐变量的信息修改生成图像的信息。

### 文本到图像

GAN-INT-CTS：对GCGAN的优化：判别器不仅需要输出图像真假，还需要分辨出生成内容是属于生成图像不真实还是生成图像不匹配。；让网络学会插值，在从不同文本提示生成的图像之间创建平滑的过渡

![9a54753af401e668f858fb4425406387](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\9a54753af401e668f858fb4425406387.png)

stackGAN

### 图像到图像

iGAN（修改原有图片）、Pix2Pix（给出草案图生出真实图），CycleGAN（根据图片生成图片，再根据生成图片生成原始图片。减少误差）

starGAN：多种标签生成同一个图像

![b4d61a512e3091b8eaa72d7f0ce67ba1](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\b4d61a512e3091b8eaa72d7f0ce67ba1.png)

## 十一、RNN与attention

### 1、RNN

**ONE-hot**：对于将word表示为向量，采用n（word的类别数量）维向量，如apple=[1,0,0,0,0],bag=[0,1,0,0,0]

这是一个票务系统，需要对目的地和时间识别分类，但是只能对当前word进行分类，没有上下文语义，不知道是到达还是离开。神经网络需要记忆。

![9baafd5019bea7599efca6d412ed5340](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\9baafd5019bea7599efca6d412ed5340.png)

依靠上下文做出决策（连乘容易梯度爆炸或者梯度消失而且只能短时记忆，采用CLIPPING或者LTSM）

![11b9adb9ebbf94a2b427f9070288165a](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\11b9adb9ebbf94a2b427f9070288165a.png)

LTSM网络：容易损失震荡，直接挂掉，采用门限，当梯度过大，进行clipping

| <img src="C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\9cb5f6fad424c4099fa14262fc34da34.png" alt="9cb5f6fad424c4099fa14262fc34da34" style="zoom:80%;" /> | ![251528b757d2d85048c5b38cc2b3747c](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\251528b757d2d85048c5b38cc2b3747c.png) | ![e369a45af6e81271225ef89e82dc3cc3](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\e369a45af6e81271225ef89e82dc3cc3.png) |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |

GRU

### 2、Attention

 解决编码有效性问题，只希望关注一部分内容![683eefd3f96230f87d134f844e1aac2b](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\683eefd3f96230f87d134f844e1aac2b.png)
$$

$$

## 十二、transformer

RNN做机器翻译，只能将所有的信息一起编码，然后用所有的信息解码，翻译某个单词并不需要这么多信息，所有采用注意力机制；另一方面，RNN只能一个一个的翻译，效率很慢，transformer可以并行

解码器：抽取元语言的特征和单词之间的关系。

![5c4fabd22781df2c9573f73d7084c819](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\5c4fabd22781df2c9573f73d7084c819.png)

嵌入层：将one-hot表示的单词映射到连续空间上，其维度于模型维度（每次的输入输出）一致，可以使用nn.Embedding函数实现，嵌入维度d_model=512，dk=dv=d_model/h

![414e919d1b9fc4df359e4fbb0cb60b7d](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\414e919d1b9fc4df359e4fbb0cb60b7d.png)

q中的一行表示一个word

![711425df87ae1ee989a39d382af32df7](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\711425df87ae1ee989a39d382af32df7.png)



| ![image-20250423213309591](C:\Users\何世钊\AppData\Roaming\Typora\typora-user-images\image-20250423213309591.png) | ![db718ed8113f2068fdc8ed3a21bc56bf](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\db718ed8113f2068fdc8ed3a21bc56bf.png) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

多头为了提取更多特征，然后连接起来，第九个w是为了降维。匹配前馈层。图中不同颜色代表不同的注意力头，当我们对“it”这个词进行编码时，一个注意力头最关注“animal”，而另一个注意力头则专注于“tire”——在某种意义上，模型对“it”这个词的表示包含了一些表示“animal”和“tire”。

![e083a4c507c8014564dedd9a35b628c1](C:\Users\何世钊\Documents\Tencent Files\1261081994\nt_qq\nt_data\Pic\2025-04\Ori\e083a4c507c8014564dedd9a35b628c1.png)

残差连接然后层归一化

Feed Forward（前馈神经网络）：就是一个两个线性层全连接神经网络，第一个升维2048，第二个降维512，对每个位置的特征进行独立的非线性变换和抽象，从而增强了模型的表达能力，使其能够学习更复杂的数据模式。
$$
FFN(x)=W 
2
​
 ⋅Activation(W 
1
​
 ⋅x+b 
1
​
 )+b 
2
​
$$
**位置编码**：为了让模型了解单词的顺序，转换器为每个输入嵌入添加了一个向量。这些向量遵循模型学习的特定模式，这有助于确定每个单词的位置，或序列中不同单词之间的距离。

### 解码器

![img](https://i-blog.csdnimg.cn/blog_migrate/e1b283d780b97fd42ffacd5a8328eb0e.gif)

![动图](https://pic3.zhimg.com/v2-7a5ae36abf5af6fcb953d5c91aef836c_b.webp)

![img](https://pic4.zhimg.com/v2-c3bfa168d1a1415ea2eeeca27a1d6a25_r.jpg)

引入了两个新的token，分别是<|im_start|>和<|im_end|>，此外，解码器一次只能接受一个token作为输入，也就是说，<|im_start|>会被作为一个输入，而"太”就是下一个预测token。

**masked 多头注意力**：在训练时，为了并行，需要将后面的单词的遮掩住及将后面的权重

